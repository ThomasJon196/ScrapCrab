# ScrapCrab

Automated webscraping combined with a dashboard.
Master project.

# Goal

- Build service Retrieve data from web (Scrapping, API, downloads) [Python, BeautifulSoup, Requests, Selenium]
- Store data in database ([InfluxDB] for time series, [Prometheus] for Monitoring)
- Create Dashboard to display data [Grafana]
- Deploy application via docker-compose. (Optionaly on continously running machine Chromebox)

# Deadline: 10.01.2023

# Resources

## Data



Download files: https://www.pegelonline.wsv.de/webservices/files (Temp & waterlevel)

Page content: https://pegel.bonn.de/php/rheinpegel.php (waterlevel)