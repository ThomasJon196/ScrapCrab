{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Datetime  Waterlevel\n",
      "0 2022-12-02 20:00:00         234\n",
      "1 2022-12-02 19:45:00         234\n",
      "2 2022-12-02 19:30:00         234\n",
      "3 2022-12-02 19:15:00         236\n",
      "4 2022-12-02 19:00:00         235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrap_data():\n",
    "    \"\"\"\n",
    "    Scraps waterlevel data from https://pegel.bonn.de/php/rheinpegel.php \n",
    "    via `Selenium` & `BeautifulSoup`.\n",
    "    \"\"\"\n",
    "    # Selenium is used to retrieve raw HTML-data\n",
    "    # Imports for Selenium + Chromebrowser\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from chromedriver_py import binary_path\n",
    "\n",
    "    service_object = Service(binary_path)\n",
    "    # Invoke new browser window\n",
    "\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=service_object, options=chrome_options)\n",
    "\n",
    "    # Navigate to website\n",
    "    driver.get(\"https://pegel.bonn.de/php/rheinpegel.php\")\n",
    "    # Select button element\n",
    "    show_table_button = driver.find_element(by='id', value='btn_table')\n",
    "    # Click button\n",
    "    show_table_button.click()\n",
    "    # Retrieve generated HTML element by id\n",
    "    waterlevel_data_element = driver.find_elements(by='id', value='dataTable')\n",
    "    # Get innerHTML content of table\n",
    "    waterlevel_data_html = waterlevel_data_element[0].get_attribute(name='innerHTML')\n",
    "    driver.close()\n",
    "\n",
    "    # BeautifulSoup used to retrieve elements inside specific HTML-tags.\n",
    "    from bs4 import BeautifulSoup\n",
    "    # Create Soup from HTML\n",
    "    soup = BeautifulSoup(waterlevel_data_html, 'html.parser')\n",
    "    # Find all table rows\n",
    "    table_rows = soup.find_all('tr')\n",
    "    table_header = table_rows[0].text\n",
    "    table_data = table_rows[1:]\n",
    "    # Split into single td (tabledata) elements\n",
    "    html_rows = [BeautifulSoup(str(table_data[i])).find_all('td')\n",
    "                 for i in range(len(table_data))]\n",
    "    rows = [[row[0].text, row[1].text] for row in html_rows]\n",
    "    date_time_raw = [row[0] for row in rows]\n",
    "    waterlevel_raw = [row[1] for row in rows]\n",
    "    return date_time_raw, waterlevel_raw\n",
    "\n",
    "def create_dataframe(date_time_raw, waterlevel_raw):\n",
    "    \"\"\"\n",
    "    Create pandas DataFrame from date_time, waterlevel data.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    dt = pd.to_datetime(date_time_raw, format=\"%m/%d/%Y, %H:%M:%S Uhr\")\n",
    "    \n",
    "    import re\n",
    "    waterlevel = [int(re.findall(pattern=r'(\\d+)', string=waterlevel_raw[i])[0])\n",
    "                  for i in range(len(waterlevel_raw))]\n",
    "    data_dict = {\n",
    "        'Datetime': dt,\n",
    "        'Waterlevel': waterlevel\n",
    "    }\n",
    "    dataFrame = pd.DataFrame(data_dict)\n",
    "    return dataFrame\n",
    "\n",
    "def map_duplicates_to_24_hour_format(dataFrame):\n",
    "    \"\"\"\n",
    "    As the dates are stored in 12 hour format wihtout indication of AM/PM,\n",
    "    later duplicates have to be mapped to the correct time in 24 hour format manually.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    duplicated_mask = dataFrame['Datetime'].duplicated(keep='last')\n",
    "    dataFrame.loc[duplicated_mask,\n",
    "                  'Datetime'] = dataFrame['Datetime'][duplicated_mask] + pd.Timedelta(hours=12)\n",
    "    return dataFrame\n",
    "\n",
    "def scrap_data_into_dataframe():\n",
    "    dt_data, waterlevel_data = scrap_data()\n",
    "    dataframe = create_dataframe(dt_data, waterlevel_data)\n",
    "    dataframe = map_duplicates_to_24_hour_format(dataframe)\n",
    "    return dataframe\n",
    "\n",
    "df = scrap_data_into_dataframe()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init influxDB credentials\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "influx_token = os.environ.get('influx_token')\n",
    "influx_org   = os.environ.get('influx_org')\n",
    "influx_bucket = os.environ.get('influx_bucket')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start up influxDB container\n",
    "import subprocess\n",
    "\n",
    "p = subprocess.Popen(\"bash run_influx_db.sh\", stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "print(p.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://www.influxdata.com/blog/getting-started-with-python-and-influxdb-v2-0/\n",
    "\n",
    "from influxdb_client import InfluxDBClient\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", \n",
    "                            token=influx_token, org=influx_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara pandas Dataframe. timestamp has to be the index column. \n",
    "df = df.rename(columns={'Datetime' : '_time'})\n",
    "df = df.set_index('_time')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write pandas dataframe to influxDB https://www.influxdata.com/blog/getting-started-with-influxdb-and-pandas/\n",
    "\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "write_api.write(influx_bucket, influx_org, record=df,\n",
    "                data_frame_measurement_name='waterlevel',\n",
    "                data_frame_tag_columns=['waterlevel'])\n",
    "\n",
    "write_api.close()\n",
    "client.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14 (main, Nov  2 2022, 10:28:32) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dcac7dca912c31587cf0d762d55b5608e12715a13951b29a2d1417c0f13007f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
